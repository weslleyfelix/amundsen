#formato de declaração do arquivo docker-compose.yaml
version: '3'

#variáveis do airflow
x-airflow-common:
  &airflow-common
  #versão
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.1.4}
  environment:
    &airflow-common-env
    AIRFLOW_CORE_EXECUTOR: CeleryExecutor
    AIRFLOW_CORE_SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW_CELERY_RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW_CELERY_BROKER_URL: redis://:@redis:6379/0
    AIRFLOW_CORE_FERNET_KEY: ''
    AIRFLOW_CORE_DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW_CORE_LOAD_EXAMPLES: 'false'
    
  #mountpoints  
  volumes:
    - /opt/airflow/dags:/opt/airflow/dags
    - /opt/airflow/logs:/opt/airflow/logs
    - /opt/airflow/plugins:/opt/airflow/plugins
    - /opt/airflow/data:/opt/airflow/data
  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}"
  depends_on:
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy


#imagens dos serviços que serão executados
services:

#serviços do airflow
  #Bancos de dados relacional útilizado para metadados
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always
    
  #faz parte do cluster de executores
  redis:
    image: redis:latest
    ports:
      - 6379:6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always
  
  #aplicação do airflow
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    restart: always

  airflow-init:
    <<: *airflow-common
    command: version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      
  #ferramenta para gerenciar os executores
  flower:
    <<: *airflow-common
    command: celery flower
    ports:
      - 5555:5555
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
  
#Serviços do amundsen  
  #realiza a construção dos grafos de metadados, trabalha em conjunto com amundsenmetadatalibrary
  neo4j:
      image: neo4j:3.5.26
      container_name: neo4j_amundsen
      environment:
        - NEO4J_AUTH=neo4j/test
      ulimits:
        nofile:
          soft: 40000
          hard: 40000
      ports:
          - 7474:7474
          - 7687:7687
      volumes:
          - ./example/docker/neo4j/conf:/var/lib/neo4j/conf
          - ./example/docker/neo4j/plugins:/var/lib/neo4j/plugins
          - ./example/backup:/backup
          - neo4j_data:/data
      networks:
        - amundsennet
  
  #índices de pesquisa trabalha em conjunto com o amundsensearchlibrary
  elasticsearch:
      image: elasticsearch:8.0.0
      container_name: es_amundsen
      #o elasticsearch consome muito da maquina por este motivo é bom colocarmos um limit mesmo que a pesquisa fique um pouco lente.
      mem_limit: 6000m
      #mem_reservation: 4000m
      ports:
          - 9200:9200
      volumes:
        - es_data:/usr/share/elasticsearch/data
      networks:
        - amundsennet
      ulimits:
        nofile:
          soft: 65536
          hard: 65536
      environment:
        - discovery.type=single-node
        - xpack.security.enabled=false
        
  #amundsensearchlibrary - serviço de pesquisa dos metadados     
  amundsensearch:
      image: amundsendev/amundsen-search:4.0.2
      container_name: amundsensearch
      ports:
        - 5001:5000
      depends_on:
        - elasticsearch
      networks:
        - amundsennet
      environment:
        - PROXY_ENDPOINT=es_amundsen
      command: gunicorn -w 2 --bind :5000 search_service.search_wsgi
   
  #amundsenmetadatalibrary - serviço de metadados 
  amundsenmetadata:
      image: amundsendev/amundsen-metadata:3.11.0
      container_name: amundsenmetadata
      depends_on:
        - neo4j
      ports:
        - 5002:5000
      networks:
        - amundsennet
      environment:
         - PROXY_HOST=bolt://neo4j_amundsen
      command: gunicorn -w 2 --bind :5000 metadata_service.metadata_wsgi
  
  #amundsenfrontendlibrary - serviço de front-end do amundsen
  amundsenfrontend:
      image: amundsendev/amundsen-frontend:4.2.0
      container_name: amundsenfrontend
      depends_on:
        - amundsenmetadata
        - amundsensearch
      ports:
        - 5000:5000
      networks:
        - amundsennet
      environment:
        - SEARCHSERVICE_BASE=http://amundsensearch:5000
        - METADATASERVICE_BASE=http://amundsenmetadata:5000
        # Only for easy config-less Quickstart bookmark evalutation. `TestConfig` extends ordinary `LocalConfig` by
        # defining `AUTH_USER_METHOD` to a hardcoded dummy user in `amundsen_application.tests.test_utils.get_test_user()`
        # See further docs in https://github.com/amundsen-io/amundsenfrontendlibrary/blob/master/docs/configuration.md#flask
        # and https://github.com/amundsen-io/amundsenfrontendlibrary/blob/master/docs/configuration.md#authentication
        - FRONTEND_SVC_CONFIG_MODULE_CLASS=amundsen_application.config.TestConfig
      command: gunicorn -w 2 --bind :5000 amundsen_application.wsgi

networks:
  amundsennet:

volumes:
  #airflow
  postgres-db-volume:
  
  #amundsen
  es_data:
  neo4j_data:
    

